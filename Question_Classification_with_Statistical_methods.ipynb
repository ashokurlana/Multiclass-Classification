{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Se96lrsuenI"
      },
      "source": [
        "# Necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLuJTVuXuenP"
      },
      "source": [
        "# Libraries\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
        "\n",
        "import pandas as pd \n",
        "\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import decomposition, ensemble\n",
        "\n",
        "import pandas, xgboost, numpy, textblob, string\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import layers, models, optimizers\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.datasets import make_classification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf2KzOFZuenR"
      },
      "source": [
        "# Handling Raw Corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "co1iDzyZuenS",
        "outputId": "723adbb5-19d6-4905-9a83-a56e6030fc82"
      },
      "source": [
        "# load the dataset\n",
        "import pandas as pd\n",
        "trainDF = pd.read_csv('data.csv', delimiter='\\t')\n",
        "#trainDF = pd.read_csv('/content/drive/MyDrive/Question Classifier Telugu/Finalized_samples.csv', delimiter=',')\n",
        "# trainDF = pd.read_csv('/content/drive/MyDrive/Question Classifier Telugu/abs_eval.csv', delimiter=',')\n",
        "\n",
        "trainDF.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              text category\n",
              "0        “బిట్వీన్ హోప్ అండ్ హిస్టరీ” రచయిత ఎవరు?       PER\n",
              "1                    మ్యాజిక్ మౌంటైన్ రచయిత ఎవరు?       PER\n",
              "2  ఆఫ్రికాలో మాలికి అత్యంత ప్రసిద్ధ పాలకుడు ఎవరు?       PER\n",
              "3                        దాస్ కాపిటల్ రచయిత ఎవరు?       PER\n",
              "4               “క్లియర్ లైట్ ఆఫ్ డే” రచయిత ఎవరు?       PER"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-547ca170-c6e3-4b7d-b73e-03e2ea631348\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>“బిట్వీన్ హోప్ అండ్ హిస్టరీ” రచయిత ఎవరు?</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>మ్యాజిక్ మౌంటైన్ రచయిత ఎవరు?</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ఆఫ్రికాలో మాలికి అత్యంత ప్రసిద్ధ పాలకుడు ఎవరు?</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>దాస్ కాపిటల్ రచయిత ఎవరు?</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>“క్లియర్ లైట్ ఆఫ్ డే” రచయిత ఎవరు?</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-547ca170-c6e3-4b7d-b73e-03e2ea631348')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-547ca170-c6e3-4b7d-b73e-03e2ea631348 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-547ca170-c6e3-4b7d-b73e-03e2ea631348');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHCdqimSsI00"
      },
      "source": [
        "## Data Splitting into Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7x0woMSMuenU",
        "outputId": "76cdd7b0-d3c5-410a-bd51-4beef3271944"
      },
      "source": [
        "# split the dataset into training and validation datasets \n",
        "train_x, test_x, train_y, test_y = model_selection.train_test_split(trainDF['text'], trainDF['category'], test_size=0.2, random_state=42)\n",
        "#print(train_y.value_counts())\n",
        "# label encode the target variable \n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "test_y = encoder.fit_transform(test_y)\n",
        "print(test_y)\n",
        "classes = list(encoder.classes_)\n",
        "print(len(classes))\n",
        "print(train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 5 5 ... 3 5 5]\n",
            "9\n",
            "[1 3 5 ... 5 4 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUQ2eFz1uenV"
      },
      "source": [
        "# Feature Engineering: Counter Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GbaSrTauenW",
        "outputId": "4eb66953-e951-4695-c1b1-9f611da64777"
      },
      "source": [
        "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
        "count_vect.fit(trainDF['text'])\n",
        "# transform the training and validation data using count vectorizer object\n",
        "xtrain_count =  count_vect.fit_transform(train_x)\n",
        "#print(xtrain_count)\n",
        "xvalid_count =  count_vect.transform(test_x)\n",
        "#print(xvalid_count)\n",
        "xtrain_count.shape, xvalid_count.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25713, 3164), (6429, 3164))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az4dm8lGuenY"
      },
      "source": [
        "# Feature Engineering: TF-IDF Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C47-Hq80uenZ"
      },
      "source": [
        "# word level tf-idf\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern = r'\\w{1,}', max_features=5000)\n",
        "tfidf_vect.fit(trainDF['text'])\n",
        "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
        "xvalid_tfidf =  tfidf_vect.transform(test_x)\n",
        "\n",
        "# ngram level tf-idf \n",
        "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', ngram_range=(2,3), max_features=25000)\n",
        "tfidf_vect_ngram.fit(trainDF['text'])\n",
        "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
        "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(test_x)\n",
        "\n",
        "# characters level tf-idf\n",
        "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', ngram_range=(2,3), max_features=25000)\n",
        "tfidf_vect_ngram_chars.fit(trainDF['text'])\n",
        "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
        "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(test_x) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndsSnLtIuena"
      },
      "source": [
        "# Model Traning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAd_REJvuenb"
      },
      "source": [
        "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
        "    # fit the training dataset on the classifier\n",
        "    classifier.fit(feature_vector_train, label)\n",
        "    \n",
        "    # predict the labels on validation dataset\n",
        "    predictions = classifier.predict(feature_vector_valid)\n",
        "\n",
        "    if is_neural_net:\n",
        "        predictions = predictions.argmax(axis=-1)\n",
        "\n",
        "    \n",
        "    acc = metrics.accuracy_score(predictions, test_y)\n",
        "    f1 = metrics.f1_score(predictions, test_y, average='weighted')\n",
        "    #print(classification_report(predictions, test_y, target_names = list(encoder.classes_)))\n",
        "    return acc, f1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekmHaWeBuDgO"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dlz-W-zJuene",
        "outputId": "3cfbc767-5676-45f7-d623-5217344c15bc"
      },
      "source": [
        "# Linear Classifier on Count Vectors\n",
        "accuracy, f1_score = train_model(linear_model.LogisticRegression(solver='sag',multi_class='multinomial', max_iter=25000), xtrain_count, train_y, xvalid_count)\n",
        "print(\"LR, Count Vectors: \", accuracy, f1_score)\n",
        "\n",
        "# Linear Classifier on Word Level TF IDF Vectors\n",
        "accuracy, f1_score = train_model(linear_model.LogisticRegression(multi_class='multinomial', solver='sag', max_iter=25000), xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print(\"LR, WordLevel TF-IDF: \", accuracy, f1_score)\n",
        "\n",
        "# Linear Classifier on Ngram Level TF IDF Vectors\n",
        "accuracy, f1_score = train_model(linear_model.LogisticRegression(multi_class='multinomial', solver='sag', max_iter=25000), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
        "print(\"LR, N-Gram Vectors: \", accuracy, f1_score)\n",
        "\n",
        "# Linear Classifier on Character Level TF IDF Vectors\n",
        "accuracy, f1_score = train_model(linear_model.LogisticRegression(multi_class='multinomial', solver='sag', max_iter=25000), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
        "print(\"LR, CharLevel Vectors: \", accuracy, f1_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR, Count Vectors:  0.9044952558718308 0.9064536356046402\n",
            "LR, WordLevel TF-IDF:  0.8962513610203764 0.9015063886574495\n",
            "LR, N-Gram Vectors:  0.8172344065951159 0.8424313889512708\n",
            "LR, CharLevel Vectors:  0.9380930160211541 0.9407068103873125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV0Ssjgyua-r"
      },
      "source": [
        "## Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTyVhfgguenc",
        "outputId": "25bf6ced-6e95-4f5a-db06-c6e3ac61fb2b"
      },
      "source": [
        "# Naive Bayes on Count Vectors\n",
        "accuracy, f1_score = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\n",
        "print(\"NB, Count Vectors: \", accuracy, f1_score)\n",
        "\n",
        "\n",
        "# Naive Bayes on Word Level TF IDF Vectors\n",
        "accuracy, f1_score = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print(\"NB, WordLevel TF-IDF: \", accuracy, f1_score)\n",
        "\n",
        "# Naive Bayes on Ngram Level TF IDF Vectors\n",
        "accuracy, f1_score = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
        "print(\"NB, N-Gram Vectors: \", accuracy, f1_score)\n",
        "\n",
        "# Naive Bayes on Character Level TF IDF Vectors\n",
        "accuracy, f1_score = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
        "print(\"NB, CharLevel Vectors: \", accuracy, f1_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NB, Count Vectors:  0.862653600871053 0.8733350496568999\n",
            "NB, WordLevel TF-IDF:  0.7553274226162701 0.8076178311156097\n",
            "NB, N-Gram Vectors:  0.7987245294758127 0.8332640889824355\n",
            "NB, CharLevel Vectors:  0.8183232228962514 0.859616293933658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90FyOdi_vYA8"
      },
      "source": [
        "## Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4jH82j1uenk",
        "outputId": "05ea9df2-0605-4616-8f8c-bbf9f9115c54"
      },
      "source": [
        "# SVM on Count Vectors\n",
        "accuracy = train_model(svm.SVC(), xtrain_count, train_y, xvalid_count)\n",
        "print(\"SVM, Count Vectors: \", accuracy)\n",
        "\n",
        "# SVM on TF IDF Vectors\n",
        "accuracy = train_model(svm.SVC(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print(\"SVM, TF-IDF Vectors: \", accuracy)\n",
        "\n",
        "# SVM on Ngram Level TF IDF Vectors\n",
        "accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
        "print(\"SVM, Ngram Level Vectors: \", accuracy)\n",
        "\n",
        "# SVM on Character Level TF IDF Vectors\n",
        "accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
        "print(\"SVM, Character Level Vectors: \", accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM, Count Vectors:  (0.9007621714107948, 0.905440544206523)\n",
            "SVM, TF-IDF Vectors:  (0.9188054129724685, 0.9219383932268962)\n",
            "SVM, Ngram Level Vectors:  (0.8425882718929849, 0.8608087228714503)\n",
            "SVM, Character Level Vectors:  (0.9499144501477679, 0.9514699362934937)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuMFEr3pw0oV"
      },
      "source": [
        "## Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElnLYhyBuenj",
        "outputId": "a946d90b-599a-452b-a097-44774ab306d8"
      },
      "source": [
        "# RF on Count Vectors\n",
        "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_count, train_y, xvalid_count)\n",
        "print(\"RF, Count Vectors: \", accuracy)\n",
        "\n",
        "# RF on Word Level TF IDF Vectors\n",
        "accuracy = train_model(ensemble.RandomForestClassifier(n_estimators=10, min_samples_split=2, n_jobs=-1), xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print(\"RF, WordLevel TF-IDF: \", accuracy)\n",
        "\n",
        "\n",
        "# RF on Word Level TF IDF Vectors\n",
        "accuracy = train_model(ensemble.RandomForestClassifier(n_estimators=10, min_samples_split=2, n_jobs=-1), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
        "print(\"RF, NgramLevel TF-IDF: \", accuracy)\n",
        "\n",
        "\n",
        "# RF on Word Level TF IDF Vectors\n",
        "accuracy = train_model(ensemble.RandomForestClassifier(n_estimators=10, min_samples_split=2, n_jobs=-1), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
        "print(\"RF, Character Level TF-IDF: \", accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RF, Count Vectors:  (0.9096282470057552, 0.9170521977322891)\n",
            "RF, WordLevel TF-IDF:  (0.8830300202208742, 0.8920590405157305)\n",
            "RF, NgramLevel TF-IDF:  (0.8436770881941204, 0.8483803088259527)\n",
            "RF, Character Level TF-IDF:  (0.9181832322289625, 0.9224476057741355)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWVmBX7rxk39"
      },
      "source": [
        "## Boosting Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQ7CMFSWxqu7",
        "outputId": "5f61a57a-d616-4049-e96a-341efd2eac60"
      },
      "source": [
        "# Extereme Gradient Boosting on Count Vectors\n",
        "accuracy = train_model(xgboost.XGBClassifier(), xtrain_count.tocsc(), train_y, xvalid_count.tocsc())\n",
        "print(\"Xgb, Count Vectors: \", accuracy)\n",
        "\n",
        "# Extereme Gradient Boosting on Word Level TF IDF Vectors\n",
        "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), train_y, xvalid_tfidf.tocsc())\n",
        "print(\"Xgb, WordLevel TF-IDF: \", accuracy)\n",
        "\n",
        "# Extereme Gradient Boosting on Character Level TF IDF Vectors\n",
        "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram_chars.tocsc(), train_y, xvalid_tfidf_ngram_chars.tocsc())\n",
        "print(\"Xgb, CharLevel Vectors: \", accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xgb, Count Vectors:  (0.8881630113547986, 0.8919517013767069)\n",
            "Xgb, WordLevel TF-IDF:  (0.8909628247005755, 0.8949147861086001)\n",
            "Xgb, CharLevel Vectors:  (0.9321822989578472, 0.934191575086161)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ_GpUqs4DfO"
      },
      "source": [
        "## MLP Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Swc5m29F4IiI",
        "outputId": "c9ccb152-2d41-4478-b290-fe350d03ca0d"
      },
      "source": [
        "# MLP with Counter Vectors\n",
        "accuracy = train_model(MLPClassifier(random_state=1, max_iter=300), xtrain_count, train_y, xvalid_count)\n",
        "print(\"MLP, Counter Vectors: \", accuracy)\n",
        "\n",
        "# MLP with TF-IDF Word Level Vectors\n",
        "accuracy = train_model(MLPClassifier(random_state=1, max_iter=300), xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print(\"MLP, TF-IDF Word Level: \", accuracy)\n",
        "\n",
        "# MLP with TF-IDF N-gram Level Vectors\n",
        "accuracy = train_model(MLPClassifier(random_state=1, max_iter=300), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
        "print(\"MLP, TF-IDF Ngram Level: \", accuracy)\n",
        "\n",
        "# MLP with TF-IDF Character Level Vectors\n",
        "accuracy = train_model(MLPClassifier(random_state=1, max_iter=300), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
        "print(\"MLP, TF-IDF Character Level: \", accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP, Counter Vectors:  (0.9083838855187432, 0.9100247845389835)\n",
            "MLP, TF-IDF Word Level:  (0.8970290869497589, 0.8981659691329391)\n",
            "MLP, TF-IDF Ngram Level:  (0.8547207963913517, 0.8569133238767289)\n",
            "MLP, TF-IDF Character Level:  (0.9491367242183855, 0.949851192890966)\n"
          ]
        }
      ]
    }
  ]
}